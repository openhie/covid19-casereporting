<div xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://hl7.org/fhir ../../src-generated/schemas/fhir-single.xsd" lang="en">
    <h3>Introduction</h3> <a name="intro"> </a>

    <p>
        Testing data for accuracy and correctness is essential for any bussiness who relies on quality data for the purpose of decision making.
        This is even more critical in healhcare as data is very commonly used to monitor the health status of a client and used to make decions in regards to diagnosis and treatment plans etc.
        <br />
        <br />
        For this reason, using an established automated testing framework can be highly beneficial to ensure data quality.
        <br />
        <br />
        In the context of <a href="index.html#technicalBackground">DISI's reference platform architecture</a>, a <strong>Central Data Repository (CDR) Testing Framework</strong> has been developed as the testing tool to support quality assurance.
        The CDR testing framework is a custom developed package that sits on top of <a href="https://www.spritecloud.com/guides/cucumber-gherkin/#:~:text=Cucumber%20is%20an%20open%2Dsource,will%20be%20explained%20later%20on." target="_blank">Cucumber and Gherkin's automation engine</a>.
    </p>

    <h3>Overview</h3> <a name="overview"> </a>

    <p>
        The Central Data Repository (CDR) Testing Framework is an automation tool that was developed by Jembi to assist with report data accuracy as well as test the data pipeline end-to-end. 
        The CDR testing framework is built on top of Cucumber, which is a general automation testing framework but also comes packaged with more specific custom developed modules which are used to query input and expected outcome datasets to assist with the measurement of data quality in the analytics platform. 
        The CDR testing framework has undergone a modular design which enables analysts, testers and developers to quite easily build new report modules to efficiently execute on-demand and regression testing processes against the data pipeline.
    </p>

    <h3>Input &amp; Expected Outcome Dataset</h3> <a name="datasets"> </a>

    <p>
        In order for the CDR Testing Framework to be considered successful in terms of end-to-end automation testing, the framework must be able to not only submit input test data to the CDR using Postman but also be able to query the analytics platform to verify whether the input data that was submitted was also successfully flattened and stored by the analytics platform.  
        Furthermore, the framework must also be able to check each and every element of the patient record to ensure that the value that is stored matches the documented expected outcome data for the patient.
        <br />
        <br />
        For the purpose of streamlined data management activities, the input and expected outcome datasets can be centrally hosted as Google Sheets. 
        The CDR Testing Framework should then fetch data from both datasets and use it during data assertions.
    </p>

    <p class="heading">Input Data</p>

    <p>
        This is the set of data that will be submitted to the CDR to mimic events at a given facility. 
        The input dataset must be defined using static data to ensure that the expected outcome data values marry up with what was submitted to the CDR. 
    </p>

    <p class="heading">Expected Outcome Data</p>

    <p>
        This is the set of data that will govern the quality and correctness of data at rest in the analytics platform. 
        In other words, the expected outcome dataset only contains patient records that must be reported on and has data values specified that correspond with the data in the input dataset and any report specification conditional logic. 
        The expected outcome dataset is a static and final outcome which the CDR testing framework will expect to see in the analytics platform. 
        If the testing framework detects a value in the analytics platform that does not correspond with the value specified for the same data element in the expected outcome dataset, the testing framework must fail that test case and immediately halt any further testing.
        <br />
        <br />
        An expected outcome dataset may have data defined for the following types of reports.
    </p>

    <ol>    
        <li>Line Listing Tabular Reports</li>
        <li>Aggregated Tabular Reports</li>
        <li>Charts</li>
    </ol>

    <h3>Summary of Benefits</h3> <a name="benefits"> </a>

    <table>
        <tr>
            <th>Benefits</th>
        </tr>
        <tr>
            <td>Able to run tests rapidly using accurate input data</td>
        </tr>
        <tr>
            <td>Able to update the input and expected outcome data in the test cases with a single click of a button - data managed solely in the input and expected outcome documents</td>
        </tr>
        <tr>
            <td>Uses behavioral-driven development - non technical stakeholders can understand the test cases</td>
        </tr>
        <tr>
            <td>Can be configured to use any middleware component or even transact directly with the analytics system (API)</td>
        </tr>
        <tr>
            <td>Input and expected outcome datasets are Google Sheet documents in Google Drive - Implements a Google Service account</td>
        </tr>
        <tr>
            <td>Able to see point of failures on a system level or patient record</td>
        </tr>
        <tr>
            <td>Able to see point of failures per patient record resulting from incorrect field-level values</td>
        </tr>
        <tr>
            <td>Supports a modular design approach - easily build custom reports using any preferred techniques and simply reference the automation framework engine to do all the work</td>
        </tr>
        <tr>
            <td>Tests the pipeline end-to-end</td>
        </tr>
         <tr>
            <td>Contributes to performance testing over the pipeline</td>
        </tr>
         <tr>
            <td>Can be included into the project's continuous integration (CI) processes so that report data quality is ensured with each build before merging into master.</td>
        </tr>
    </table>
</div>